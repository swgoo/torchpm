{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeoun9/torchpm/blob/main/examples/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WllWbwIhca9I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/yeoun9/torchpm.git\n",
            "  Cloning https://github.com/yeoun9/torchpm.git to c:\\users\\sungwoo\\appdata\\local\\temp\\pip-req-build-6ovpf8fq\n",
            "  Resolved https://github.com/yeoun9/torchpm.git to commit f0fc85b46ba8f318c41e03956238c29ba9cd5205\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Requirement already satisfied: torch>=1.3.0 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm==0.0.3) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm==0.0.3) (1.22.3)\n",
            "Requirement already satisfied: torchdiffeq>=0.2.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm==0.0.3) (0.2.2)\n",
            "Requirement already satisfied: sympy>=1.7.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm==0.0.3) (1.10)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.7.1->torchpm==0.0.3) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.3.0->torchpm==0.0.3) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchdiffeq>=0.2.1->torchpm==0.0.3) (1.8.0)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  Running command git clone --filter=blob:none --quiet https://github.com/yeoun9/torchpm.git 'C:\\Users\\sungwoo\\AppData\\Local\\Temp\\pip-req-build-6ovpf8fq'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sympytorch in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.1.1)\n",
            "Requirement already satisfied: sympy>=1.7.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympytorch) (1.10)\n",
            "Requirement already satisfied: torch>=1.6.0 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympytorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.7.1->sympytorch) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.6.0->sympytorch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/yeoun9/torchpm.git\n",
        "! pip install sympytorch\n",
        "from torchpm import *\n",
        "from torchpm.data import CSVDataset\n",
        "from torchpm.estimated_parameter import *\n",
        "import torch as tc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "coHSs8ZfBEfV"
      },
      "source": [
        "# Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "AqeOy6Vrcyl-"
      },
      "outputs": [],
      "source": [
        "tc.set_default_dtype(tc.float64)\n",
        "\n",
        "#TODO 주의사항 다운로드 할때 캐쉬 파일이 있으면 업데이트가 되지 않아서 이상하게 계산되는 경우가 있으니 주의해야함.\n",
        "dataset_file_path = 'https://raw.githubusercontent.com/yeoun9/torchpm/main/examples/THEO.csv'\n",
        "# dataset_file_path = './THEO.csv'\n",
        "column_names = ['ID', 'AMT', 'TIME', 'DV', 'CMT', 'MDV', 'RATE', 'BWT']\n",
        "\n",
        "#TODO CPU랑 GPU랑 차이남. 근데 float64나 float32를 기본으로 설정해서 똑같이 나오도록 유도\n",
        "device = tc.device(\"cuda:0\" if tc.cuda.is_available() else \"cpu\")\n",
        "# device = tc.device(\"cpu\")\n",
        "dataset = CSVDataset(dataset_file_path, column_names, device)\n",
        "\n",
        "class BasementModel(predfunction.PredictionFunctionByTime) :\n",
        "    def __init__(self, dataset: tc.utils.data.Dataset, column_names: Iterable[str], output_column_names: Iterable[str], *args, **kwargs):\n",
        "        super().__init__(dataset, column_names, output_column_names, *args, **kwargs)\n",
        "\n",
        "        self.theta_0 = Theta(1.5, 0, 10)\n",
        "        self.theta_1 = Theta(32, 0, 50)\n",
        "        self.theta_2 = Theta(0.08, 0, 1)\n",
        "\n",
        "        self.eta_0 = Eta()\n",
        "        self.eta_1 = Eta()\n",
        "        self.eta_2 = Eta()\n",
        "\n",
        "        self.eps_0 = Eps()\n",
        "        self.eps_1 = Eps()\n",
        "\n",
        "        self.gut_model = linearode.Comp1GutModelFunction()\n",
        "\n",
        "        self.initialize()\n",
        "    \n",
        "    def _calculate_parameters(self, **para):\n",
        "        k_a = self.theta_0()*tc.exp(self.eta_0())\n",
        "        #TODO\n",
        "        v = self.theta_1()*tc.exp(self.eta_1())#*para['BWT']/70\n",
        "        k_e = self.theta_2()*tc.exp(self.eta_2())\n",
        "        para['AMT'] = tc.tensor(320., device=self.dataset.device)\n",
        "        return para | {\"k_a\": k_a, \"v\": v, \"k_e\": k_e}\n",
        "\n",
        "    def _calculate_preds(self, t, amt, rate, **para) -> tc.Tensor:\n",
        "        dose = amt\n",
        "        k_a = para['k_a']\n",
        "        v = para['v']\n",
        "        k_e = para['k_e']\n",
        "        # return (dose / v * k_a) / (k_a - k_e) * (tc.exp(-k_e*t) - tc.exp(-k_a*t))\n",
        "        ############ Sympy Version Function #############\n",
        "        comps = self.gut_model(t, k_a, k_e, dose)\n",
        "        return comps[1]/v\n",
        "        \n",
        "    def _calculate_error(self, y_pred, **para) -> tc.Tensor:\n",
        "        return y_pred +  y_pred * self.eps_0() + self.eps_1(), para\n",
        "\n",
        "pred_function_module = BasementModel(dataset = dataset,\n",
        "                            column_names = column_names,\n",
        "                            output_column_names=['ID'],)\n",
        "\n",
        "omega = Omega([tc.tensor([0.4397,\n",
        "                        0.0575,  0.0198, \n",
        "                        -0.0069,  0.0116,  0.0205], device = device)], [False])\n",
        "sigma = Sigma( [tc.tensor([0.0177, 0.0762], device = device)], [True])\n",
        "\n",
        "model = models.FOCEInter(pred_function_module, \n",
        "                        theta_names=['0', '1', '2'],\n",
        "                        eta_names=[['0', '1','2']], \n",
        "                        eps_names= [['0','1']], \n",
        "                        omega=omega, \n",
        "                        sigma=sigma)\n",
        "\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gADOA1QjBLsj"
      },
      "source": [
        "#Model Fitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h-KsW5gc2V2",
        "outputId": "8cb8d5b3-94fd-4f6f-90fb-658f7d686df9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running_time :  0.7493245601654053 \t total_loss: tensor(566.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  1.3314123153686523 \t total_loss: tensor(329.6858, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  1.9162180423736572 \t total_loss: tensor(264.6675, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  2.4984073638916016 \t total_loss: tensor(197.2443, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  3.075737237930298 \t total_loss: tensor(186.1239, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  3.6533355712890625 \t total_loss: tensor(173.8079, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  4.227323770523071 \t total_loss: tensor(171.3669, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  4.814727306365967 \t total_loss: tensor(158.5640, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  5.399420976638794 \t total_loss: tensor(135.5841, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  5.98532509803772 \t total_loss: tensor(150.4642, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  6.5684967041015625 \t total_loss: tensor(119.2757, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  7.162203311920166 \t total_loss: tensor(123.2711, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  7.743695974349976 \t total_loss: tensor(107.0605, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  8.32226037979126 \t total_loss: tensor(108.8090, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  8.9155912399292 \t total_loss: tensor(100.0049, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  9.496831178665161 \t total_loss: tensor(99.2061, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  10.079509973526001 \t total_loss: tensor(98.4083, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  10.660722255706787 \t total_loss: tensor(97.1203, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  11.241178512573242 \t total_loss: tensor(95.1439, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  11.826737403869629 \t total_loss: tensor(94.4952, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  12.40765118598938 \t total_loss: tensor(93.9030, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  12.988741874694824 \t total_loss: tensor(93.7035, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  13.576364278793335 \t total_loss: tensor(93.5256, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  14.163329839706421 \t total_loss: tensor(93.2341, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  14.751335382461548 \t total_loss: tensor(92.8931, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  15.336445569992065 \t total_loss: tensor(92.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  15.930243968963623 \t total_loss: tensor(92.6744, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  16.52249002456665 \t total_loss: tensor(92.6348, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  17.11325216293335 \t total_loss: tensor(92.5679, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  17.702202796936035 \t total_loss: tensor(92.5328, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  18.291878700256348 \t total_loss: tensor(92.4876, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  18.880857467651367 \t total_loss: tensor(92.4488, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  19.47461986541748 \t total_loss: tensor(92.4204, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  20.060326099395752 \t total_loss: tensor(92.3603, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  20.647436380386353 \t total_loss: tensor(92.3540, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  21.2347412109375 \t total_loss: tensor(92.3158, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  21.823244094848633 \t total_loss: tensor(92.2970, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  22.42145323753357 \t total_loss: tensor(92.2749, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  23.005670070648193 \t total_loss: tensor(92.2481, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  23.58654022216797 \t total_loss: tensor(92.2001, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  24.173242568969727 \t total_loss: tensor(92.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  24.780643224716187 \t total_loss: tensor(92.1701, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  25.378329277038574 \t total_loss: tensor(92.1670, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  25.978347301483154 \t total_loss: tensor(92.1619, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  26.563701629638672 \t total_loss: tensor(92.1570, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  27.15621256828308 \t total_loss: tensor(92.1514, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  27.74128270149231 \t total_loss: tensor(92.1478, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  28.323223114013672 \t total_loss: tensor(92.1462, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  28.902618646621704 \t total_loss: tensor(92.1453, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  29.485476970672607 \t total_loss: tensor(92.1445, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  30.06926918029785 \t total_loss: tensor(92.1429, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  30.652225971221924 \t total_loss: tensor(92.1428, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  31.23178267478943 \t total_loss: tensor(92.1411, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  31.815271377563477 \t total_loss: tensor(92.1406, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  32.40035080909729 \t total_loss: tensor(92.1397, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  32.98688507080078 \t total_loss: tensor(92.1385, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  33.58474159240723 \t total_loss: tensor(92.1379, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  34.16976594924927 \t total_loss: tensor(92.1360, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  34.75218081474304 \t total_loss: tensor(92.1352, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  35.34963774681091 \t total_loss: tensor(92.1345, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  35.934260845184326 \t total_loss: tensor(92.1335, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  36.52934741973877 \t total_loss: tensor(92.1326, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  37.16633057594299 \t total_loss: tensor(92.1318, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  37.74663853645325 \t total_loss: tensor(92.1313, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  38.32462191581726 \t total_loss: tensor(92.1303, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  38.90170216560364 \t total_loss: tensor(92.1295, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  39.48036193847656 \t total_loss: tensor(92.1286, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  40.05722904205322 \t total_loss: tensor(92.1277, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  40.63795590400696 \t total_loss: tensor(92.1273, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  41.219298124313354 \t total_loss: tensor(92.1270, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  41.81429195404053 \t total_loss: tensor(92.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  42.40431523323059 \t total_loss: tensor(92.1269, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  42.99373960494995 \t total_loss: tensor(92.1268, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  43.58524560928345 \t total_loss: tensor(92.1266, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  44.17339563369751 \t total_loss: tensor(92.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  44.758628368377686 \t total_loss: tensor(92.1264, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  45.34542751312256 \t total_loss: tensor(92.1263, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  45.936402320861816 \t total_loss: tensor(92.1262, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  46.5232458114624 \t total_loss: tensor(92.1260, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  47.113367319107056 \t total_loss: tensor(92.1261, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  47.70121693611145 \t total_loss: tensor(92.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  48.29076623916626 \t total_loss: tensor(92.1258, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  48.883267402648926 \t total_loss: tensor(92.1257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  49.477558851242065 \t total_loss: tensor(92.1257, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  50.06930661201477 \t total_loss: tensor(92.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  50.658334493637085 \t total_loss: tensor(92.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  51.2515172958374 \t total_loss: tensor(92.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  51.85265350341797 \t total_loss: tensor(92.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  52.452229022979736 \t total_loss: tensor(92.1254, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  53.05660629272461 \t total_loss: tensor(92.1253, device='cuda:0', grad_fn=<AddBackward0>)\n",
            "running_time :  53.658286333084106 \t total_loss: tensor(92.1253, device='cuda:0', grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FOCEInter(\n",
              "  (pred_function_module): BasementModel(\n",
              "    (theta_0): Theta()\n",
              "    (theta_1): Theta()\n",
              "    (theta_2): Theta()\n",
              "    (eta_0): Eta(\n",
              "      (parameter_values): ParameterDict(\n",
              "          (1): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (2): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (3): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (4): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (5): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (6): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (7): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (8): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (9): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (10): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (11): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (12): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "      )\n",
              "    )\n",
              "    (eta_1): Eta(\n",
              "      (parameter_values): ParameterDict(\n",
              "          (1): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (2): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (3): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (4): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (5): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (6): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (7): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (8): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (9): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (10): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (11): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (12): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "      )\n",
              "    )\n",
              "    (eta_2): Eta(\n",
              "      (parameter_values): ParameterDict(\n",
              "          (1): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (2): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (3): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (4): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (5): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (6): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (7): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (8): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (9): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (10): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (11): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "          (12): Parameter containing: [torch.cuda.DoubleTensor of size  (GPU 0)]\n",
              "      )\n",
              "    )\n",
              "    (eps_0): Eps()\n",
              "    (eps_1): Eps()\n",
              "    (gut_model): Comp1GutModelFunction(\n",
              "      (model): SymPyModule(expressions=(d*exp(-k_01*t), d*k_01*exp(-k_11*t)/(k_01 - k_11) - d*k_01*exp(-k_01*t)/(k_01 - k_11)))\n",
              "    )\n",
              "  )\n",
              "  (omega): Omega(\n",
              "    (parameter_values): ParameterList(  (0): Parameter containing: [torch.cuda.DoubleTensor of size 6 (GPU 0)])\n",
              "  )\n",
              "  (sigma): Sigma(\n",
              "    (parameter_values): ParameterList(  (0): Parameter containing: [torch.cuda.DoubleTensor of size 2 (GPU 0)])\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit_population(learning_rate = 1, tolerance_grad = 1e-5, tolerance_change= 1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3ceRLKQBRi3"
      },
      "source": [
        "# Result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "id": "mopJF9Oqc6bf",
        "outputId": "38c9c57f-a6b3-4082-c0ba-feb799fc8000"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: _Node(\n  (_args): ModuleList(\n    (0): _Node(\n      (_args): ModuleList(\n        (0): _Node()\n        (1): _Node()\n        (2): _Node()\n      )\n    )\n  )\n)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: _Node(\n  (_args): ModuleList(\n    (0): _Node()\n    (1): _Node()\n    (2): _Node()\n  )\n)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10584/807624127.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meval_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time-pred'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\models.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0momega\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmdv_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[0mid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_function_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_column_names\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ID'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mpred_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_function_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0metas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'etas'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\predfunction.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mf_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparameters_sliced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_cur\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10584/4274769891.py\u001b[0m in \u001b[0;36m_calculate_preds\u001b[1;34m(self, t, amt, rate, **para)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# return (dose / v * k_a) / (k_a - k_e) * (tc.exp(-k_e*t) - tc.exp(-k_a*t))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m############ Sympy Version Function #############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mcomps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgut_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\linearode.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t, k01, k11, dose)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_01\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_11\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mk11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;31m#TODO sympy 수식 저장해서 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, **symbols)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemodict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                 \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    132\u001b[0m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0marg_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemodict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m                 \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mfn_\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "eval_result = model.descale().evaluate()\n",
        "\n",
        "print('time-pred')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "for id, time_data in eval_result['times'].items() :\n",
        "    y_pred = eval_result['preds'][id]\n",
        "    ax.plot(time_data.to('cpu'), y_pred.detach().to('cpu').numpy())\n",
        "plt.show()\n",
        "\n",
        "print('time-cwres')\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "for id, time_data in eval_result['times'].items() :\n",
        "    cwres_value = eval_result['cwress'][id]\n",
        "    ax.plot(time_data.masked_select(eval_result['mdv_masks'][id]).to('cpu'), cwres_value.detach().to('cpu').numpy())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E634uDe_c7-o",
        "outputId": "80202da3-ee65-4246-981b-29538edc0e4e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_loss\n",
            "tensor(92.1253, device='cuda:0')\n",
            "losses\n",
            "{'1': 20.09432054779129, '2': 17.494065704837382, '3': -1.2956903537397277, '4': 9.294098169619797, '5': 20.158547903457574, '6': 4.118904719513731, '7': 1.2929950559537637, '8': 3.9580997252746535, '9': 2.977555221370233, '10': 4.822593456769802, '11': -2.4200388653017093, '12': 11.629896902603614}\n",
            "times\n",
            "{'1': tensor([ 0.0000,  0.0000,  0.2500,  0.5700,  1.1200,  2.0200,  3.8200,  5.1000,\n",
            "         7.0300,  9.0500, 12.1200, 24.3700], device='cuda:0',\n",
            "       dtype=torch.float32), '2': tensor([ 0.0000,  0.0000,  0.2700,  0.5200,  1.0000,  1.9200,  3.5000,  5.0200,\n",
            "         7.0300,  9.0000, 12.0000, 24.3000], device='cuda:0',\n",
            "       dtype=torch.float32), '3': tensor([ 0.0000,  0.0000,  0.2700,  0.5800,  1.0200,  2.0200,  3.6200,  5.0800,\n",
            "         7.0700,  9.0000, 12.1500, 24.1700], device='cuda:0',\n",
            "       dtype=torch.float32), '4': tensor([ 0.0000,  0.0000,  0.3500,  0.6000,  1.0700,  2.1300,  3.5000,  5.0200,\n",
            "         7.0200,  9.0200, 11.9800, 24.6500], device='cuda:0',\n",
            "       dtype=torch.float32), '5': tensor([ 0.0000,  0.0000,  0.3000,  0.5200,  1.0000,  2.0200,  3.5000,  5.0200,\n",
            "         7.0200,  9.1000, 12.0000, 24.3500], device='cuda:0',\n",
            "       dtype=torch.float32), '6': tensor([ 0.0000,  0.0000,  0.2700,  0.5800,  1.1500,  2.0300,  3.5700,  5.0000,\n",
            "         7.0000,  9.2200, 12.1000, 23.8500], device='cuda:0',\n",
            "       dtype=torch.float32), '7': tensor([ 0.0000,  0.0000,  0.2500,  0.5000,  1.0200,  2.0200,  3.4800,  5.0000,\n",
            "         6.9800,  9.0000, 12.0500, 24.2200], device='cuda:0',\n",
            "       dtype=torch.float32), '8': tensor([ 0.0000,  0.0000,  0.2500,  0.5200,  0.9800,  2.0200,  3.5300,  5.0500,\n",
            "         7.1500,  9.0700, 12.1000, 24.1200], device='cuda:0',\n",
            "       dtype=torch.float32), '9': tensor([ 0.0000,  0.0000,  0.3000,  0.6300,  1.0500,  2.0200,  3.5300,  5.0200,\n",
            "         7.1700,  8.8000, 11.6000, 24.4300], device='cuda:0',\n",
            "       dtype=torch.float32), '10': tensor([ 0.0000,  0.0000,  0.3700,  0.7700,  1.0200,  2.0500,  3.5500,  5.0500,\n",
            "         7.0800,  9.3800, 12.1000, 23.7000], device='cuda:0',\n",
            "       dtype=torch.float32), '11': tensor([ 0.0000,  0.0000,  0.2500,  0.5000,  0.9800,  1.9800,  3.6000,  5.0200,\n",
            "         7.0300,  9.0300, 12.1200, 24.0800], device='cuda:0',\n",
            "       dtype=torch.float32), '12': tensor([ 0.0000,  0.0000,  0.2500,  0.5000,  1.0000,  2.0000,  3.5200,  5.0700,\n",
            "         7.0700,  9.0300, 12.0500, 24.1500], device='cuda:0',\n",
            "       dtype=torch.float32)}\n",
            "preds\n",
            "{'1': tensor([ 0.0000,  0.0000,  3.3878,  6.2680,  8.8789, 10.1489,  9.6703,  8.9439,\n",
            "         7.8899,  6.9108,  5.6495,  2.5281], device='cuda:0',\n",
            "       grad_fn=<AddBackward0>), '2': tensor([0.0000, 0.0000, 3.9708, 6.0099, 7.6856, 7.9900, 7.0599, 6.1500, 5.1189,\n",
            "        4.2760, 3.2512, 1.0573], device='cuda:0', grad_fn=<AddBackward0>), '3': tensor([0.0000, 0.0000, 4.2721, 6.6981, 8.0021, 8.1202, 7.1579, 6.3147, 5.3206,\n",
            "        4.5062, 3.4360, 1.2209], device='cuda:0', grad_fn=<AddBackward0>), '4': tensor([0.0000, 0.0000, 3.1329, 4.6953, 6.5891, 8.1057, 7.9405, 7.1237, 6.0053,\n",
            "        5.0342, 3.8728, 1.2594], device='cuda:0', grad_fn=<AddBackward0>), '5': tensor([0.0000, 0.0000, 3.8336, 5.6938, 8.0185, 9.2835, 8.7299, 7.7917, 6.6522,\n",
            "        5.6383, 4.4770, 1.6765], device='cuda:0', grad_fn=<AddBackward0>), '6': tensor([0.0000, 0.0000, 1.8793, 3.4593, 5.2363, 6.3054, 6.2091, 5.5125, 4.4864,\n",
            "        3.5269, 2.5737, 0.7103], device='cuda:0', grad_fn=<AddBackward0>), '7': tensor([0.0000, 0.0000, 1.4145, 2.5872, 4.4032, 6.2628, 6.9222, 6.5542, 5.6325,\n",
            "        4.6711, 3.4582, 1.0159], device='cuda:0', grad_fn=<AddBackward0>), '8': tensor([0.0000, 0.0000, 2.6828, 4.6240, 6.4764, 7.5390, 6.9675, 6.0905, 5.0054,\n",
            "        4.1791, 3.1431, 1.0153], device='cuda:0', grad_fn=<AddBackward0>), '9': tensor([0.0000, 0.0000, 6.7371, 7.6996, 7.5963, 7.0045, 6.1544, 5.4167, 4.5052,\n",
            "        3.9179, 3.0821, 1.0265], device='cuda:0', grad_fn=<AddBackward0>), '10': tensor([0.0000, 0.0000, 2.8576, 5.1006, 6.1564, 8.6295, 9.4041, 8.9658, 7.9097,\n",
            "        6.7042, 5.4748, 2.2914], device='cuda:0', grad_fn=<AddBackward0>), '11': tensor([0.0000, 0.0000, 4.8471, 6.6889, 7.4666, 7.0083, 6.0226, 5.2692, 4.3610,\n",
            "        3.6127, 2.7010, 0.8763], device='cuda:0', grad_fn=<AddBackward0>), '12': tensor([0.0000, 0.0000, 2.2623, 4.0187, 6.4067, 8.4742, 8.7208, 7.9662, 6.8038,\n",
            "        5.7710, 4.4639, 1.5917], device='cuda:0', grad_fn=<AddBackward0>)}\n",
            "cwress\n",
            "{'1': tensor([ 2.6506, -1.0732,  0.4018,  1.5748,  0.0693, -0.2462,  0.1535,  0.2901,\n",
            "         0.6877,  1.0993,  2.3815], device='cuda:0', grad_fn=<MvBackward0>), '2': tensor([ 0.0000, -2.9962,  2.7904,  0.7579,  0.1315, -0.5193, -0.4015,  0.0590,\n",
            "         0.1135, -0.7709, -0.6531], device='cuda:0', grad_fn=<MvBackward0>), '3': tensor([ 0.0000,  0.4773,  0.4448,  0.2421, -0.4238,  0.1677, -0.3069, -0.2011,\n",
            "         0.4254,  0.3258, -0.6544], device='cuda:0', grad_fn=<MvBackward0>), '4': tensor([ 0.0000, -2.6896, -0.4376,  1.8891,  0.1076, -0.3671, -0.2052, -0.2381,\n",
            "         0.4089,  0.5041, -0.4172], device='cuda:0', grad_fn=<MvBackward0>), '5': tensor([ 0.0000, -2.8061,  0.1796,  3.2921,  0.2437,  0.1999, -0.0455,  0.6173,\n",
            "         0.4446, -0.0816, -0.2923], device='cuda:0', grad_fn=<MvBackward0>), '6': tensor([ 0.0000, -2.0672, -1.4565,  0.7740, -0.6812, -1.2406, -1.0936, -1.0364,\n",
            "        -0.4440,  0.1599,  0.5413], device='cuda:0', grad_fn=<MvBackward0>), '7': tensor([ 0.5373, -2.1762, -1.3217, -0.0533, -0.5417, -0.3598, -0.1359, -0.5595,\n",
            "        -0.4520,  0.0690,  0.3067], device='cuda:0', grad_fn=<MvBackward0>), '8': tensor([ 0.0000,  0.9324, -2.3084,  0.8365, -0.1745, -0.6278, -0.4867, -0.6113,\n",
            "         0.4171, -0.4697,  0.6786], device='cuda:0', grad_fn=<MvBackward0>), '9': tensor([ 0.0000,  1.6443,  1.1219, -0.9092, -1.1842, -1.0053, -0.0513, -0.7147,\n",
            "         0.0586, -0.0429,  0.2672], device='cuda:0', grad_fn=<MvBackward0>), '10': tensor([ 0.8597, -0.2153, -0.1810, -0.0335, -0.7870,  0.8471,  0.5748,  0.5896,\n",
            "         0.9571,  0.7125,  0.5469], device='cuda:0', grad_fn=<MvBackward0>), '11': tensor([ 0.0000,  0.5856,  0.8222,  0.2406, -0.7006, -0.6731, -0.5424, -0.3143,\n",
            "        -0.4139, -0.4079, -0.2584], device='cuda:0', grad_fn=<MvBackward0>), '12': tensor([ 0.0000, -2.7918, -0.5731,  1.0968,  0.8515,  0.9386,  0.7289, -0.0606,\n",
            "         0.5243,  0.1757, -1.3556], device='cuda:0', grad_fn=<MvBackward0>)}\n",
            "mdv_masks\n",
            "{'1': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '2': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '3': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '4': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '5': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '6': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '7': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '8': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '9': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '10': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '11': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0'), '12': tensor([False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "         True,  True], device='cuda:0')}\n",
            "parameters\n",
            "{'1': {'ID': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '2': {'ID': tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '3': {'ID': tensor([3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3., 3.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '4': {'ID': tensor([4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4., 4.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '5': {'ID': tensor([5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5., 5.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '6': {'ID': tensor([6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6., 6.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '7': {'ID': tensor([7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7., 7.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '8': {'ID': tensor([8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8., 8.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '9': {'ID': tensor([9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9., 9.], device='cuda:0',\n",
            "       dtype=torch.float32)}, '10': {'ID': tensor([10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10., 10.],\n",
            "       device='cuda:0', dtype=torch.float32)}, '11': {'ID': tensor([11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11., 11.],\n",
            "       device='cuda:0', dtype=torch.float32)}, '12': {'ID': tensor([12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12., 12.],\n",
            "       device='cuda:0', dtype=torch.float32)}}\n"
          ]
        }
      ],
      "source": [
        "for k, v in eval_result.items():\n",
        "    print(k)\n",
        "    print(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fTPa6hac9Mu",
        "outputId": "d6d3e40a-03dd-4c62-ba46-3f5661dfc50b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "id 1\n",
            "id 2\n",
            "id 3\n",
            "id 4\n",
            "id 5\n",
            "id 6\n",
            "id 7\n",
            "id 8\n",
            "id 9\n",
            "id 10\n",
            "id 11\n",
            "id 12\n",
            "{'cov': tensor([[ 3.5608e-03,  2.6993e-02, -1.5673e-04,  9.9913e-04,  8.2931e-05,\n",
            "          9.8599e-05, -7.3628e-07,  1.8294e-04,  3.3704e-04, -3.8012e-04,\n",
            "          3.2504e-03],\n",
            "        [ 2.6993e-02,  3.4340e-01, -1.4778e-03,  1.3187e-03, -3.4414e-03,\n",
            "          1.6031e-04, -3.1016e-03,  1.3220e-03,  2.5405e-03, -1.1178e-03,\n",
            "          1.0364e-02],\n",
            "        [-1.5673e-04, -1.4778e-03,  7.7138e-06, -9.8072e-06,  6.7894e-06,\n",
            "         -3.3161e-06,  4.9767e-06, -8.5714e-06, -1.5218e-05,  1.4079e-05,\n",
            "         -1.1653e-04],\n",
            "        [ 9.9913e-04,  1.3187e-03, -9.8072e-06,  2.5533e-02,  3.2433e-03,\n",
            "          2.3392e-04, -3.5577e-04, -2.2654e-04, -3.5223e-04, -1.8353e-04,\n",
            "         -2.5278e-03],\n",
            "        [ 8.2931e-05, -3.4414e-03,  6.7894e-06,  3.2433e-03,  6.3207e-04,\n",
            "          6.4848e-05,  2.0963e-04, -1.9151e-05, -6.6566e-05, -4.6176e-05,\n",
            "         -1.5864e-04],\n",
            "        [ 9.8599e-05,  1.6031e-04, -3.3161e-06,  2.3392e-04,  6.4848e-05,\n",
            "          1.7737e-05,  3.9031e-05,  1.2785e-05,  1.3262e-05, -1.6915e-05,\n",
            "          1.2526e-04],\n",
            "        [-7.3628e-07, -3.1016e-03,  4.9767e-06, -3.5577e-04,  2.0963e-04,\n",
            "          3.9031e-05,  3.1191e-04,  1.9898e-05, -1.7051e-05, -2.4495e-05,\n",
            "          1.8135e-04],\n",
            "        [ 1.8294e-04,  1.3220e-03, -8.5714e-06, -2.2654e-04, -1.9151e-05,\n",
            "          1.2785e-05,  1.9898e-05,  2.2556e-05,  3.2947e-05, -2.1451e-05,\n",
            "          2.4215e-04],\n",
            "        [ 3.3704e-04,  2.5405e-03, -1.5218e-05, -3.5223e-04, -6.6566e-05,\n",
            "          1.3262e-05, -1.7051e-05,  3.2947e-05,  6.0731e-05, -3.6446e-05,\n",
            "          4.7648e-04],\n",
            "        [-3.8012e-04, -1.1178e-03,  1.4079e-05, -1.8353e-04, -4.6176e-05,\n",
            "         -1.6915e-05, -2.4495e-05, -2.1451e-05, -3.6446e-05,  7.5574e-05,\n",
            "         -5.2706e-04],\n",
            "        [ 3.2504e-03,  1.0364e-02, -1.1653e-04, -2.5278e-03, -1.5864e-04,\n",
            "          1.2526e-04,  1.8135e-04,  2.4215e-04,  4.7648e-04, -5.2706e-04,\n",
            "          5.8271e-03]], device='cuda:0'), 'se': tensor([0.0597, 0.5860, 0.0028, 0.1598, 0.0251, 0.0042, 0.0177, 0.0047, 0.0078,\n",
            "        0.0087, 0.0763], device='cuda:0'), 'cor': tensor([[ 1.0000e+00,  7.7192e-01, -9.4566e-01,  1.0478e-01,  5.5279e-02,\n",
            "          3.9234e-01, -6.9864e-04,  6.4550e-01,  7.2476e-01, -7.3276e-01,\n",
            "          7.1356e-01],\n",
            "        [ 7.7192e-01,  1.0000e+00, -9.0798e-01,  1.4083e-02, -2.3359e-01,\n",
            "          6.4957e-02, -2.9969e-01,  4.7501e-01,  5.5631e-01, -2.1942e-01,\n",
            "          2.3169e-01],\n",
            "        [-9.4566e-01, -9.0798e-01,  1.0000e+00, -2.2098e-02,  9.7234e-02,\n",
            "         -2.8351e-01,  1.0146e-01, -6.4980e-01, -7.0308e-01,  5.8310e-01,\n",
            "         -5.4966e-01],\n",
            "        [ 1.0478e-01,  1.4083e-02, -2.2098e-02,  1.0000e+00,  8.0734e-01,\n",
            "          3.4760e-01, -1.2607e-01, -2.9850e-01, -2.8286e-01, -1.3212e-01,\n",
            "         -2.0724e-01],\n",
            "        [ 5.5279e-02, -2.3359e-01,  9.7234e-02,  8.0734e-01,  1.0000e+00,\n",
            "          6.1246e-01,  4.7212e-01, -1.6039e-01, -3.3975e-01, -2.1127e-01,\n",
            "         -8.2660e-02],\n",
            "        [ 3.9234e-01,  6.4957e-02, -2.8351e-01,  3.4760e-01,  6.1246e-01,\n",
            "          1.0000e+00,  5.2476e-01,  6.3919e-01,  4.0408e-01, -4.6201e-01,\n",
            "          3.8964e-01],\n",
            "        [-6.9864e-04, -2.9969e-01,  1.0146e-01, -1.2607e-01,  4.7212e-01,\n",
            "          5.2476e-01,  1.0000e+00,  2.3722e-01, -1.2389e-01, -1.5954e-01,\n",
            "          1.3452e-01],\n",
            "        [ 6.4550e-01,  4.7501e-01, -6.4980e-01, -2.9850e-01, -1.6039e-01,\n",
            "          6.3919e-01,  2.3722e-01,  1.0000e+00,  8.9016e-01, -5.1955e-01,\n",
            "          6.6792e-01],\n",
            "        [ 7.2476e-01,  5.5631e-01, -7.0308e-01, -2.8286e-01, -3.3975e-01,\n",
            "          4.0408e-01, -1.2389e-01,  8.9016e-01,  1.0000e+00, -5.3798e-01,\n",
            "          8.0095e-01],\n",
            "        [-7.3276e-01, -2.1942e-01,  5.8310e-01, -1.3212e-01, -2.1127e-01,\n",
            "         -4.6201e-01, -1.5954e-01, -5.1955e-01, -5.3798e-01,  1.0000e+00,\n",
            "         -7.9423e-01],\n",
            "        [ 7.1356e-01,  2.3169e-01, -5.4966e-01, -2.0724e-01, -8.2660e-02,\n",
            "          3.8964e-01,  1.3452e-01,  6.6792e-01,  8.0095e-01, -7.9423e-01,\n",
            "          1.0000e+00]], device='cuda:0'), 'ei_values': tensor([3.3271e-05, 8.2359e-05, 4.1468e-03, 1.2669e-02, 1.9620e-02, 1.5907e-01,\n",
            "        5.8613e-01, 8.3120e-01, 1.6295e+00, 2.5675e+00, 5.1901e+00],\n",
            "       device='cuda:0'), 'inv_cov': tensor([[ 1.7914e+05, -1.6025e+03,  1.9542e+06,  1.1087e+05, -9.1071e+05,\n",
            "          9.2732e+05, -2.1825e+05,  6.1188e+06, -6.0279e+06,  1.4172e+06,\n",
            "          3.1898e+05],\n",
            "        [-1.6025e+03,  4.7382e+02,  8.9598e+04, -3.2546e+03,  3.2876e+04,\n",
            "         -6.6393e+04, -2.4185e+04,  1.0335e+05, -3.6635e+04, -3.2503e+03,\n",
            "          1.9129e+03],\n",
            "        [ 1.9542e+06,  8.9598e+04,  4.7295e+07,  5.5741e+05, -2.9399e+06,\n",
            "         -6.1477e+06, -9.0561e+06,  1.0457e+08, -8.5346e+07,  1.7266e+07,\n",
            "          4.4669e+06],\n",
            "        [ 1.1087e+05, -3.2546e+03,  5.5741e+05,  1.5856e+05, -1.4292e+06,\n",
            "          2.2568e+06,  4.9524e+05,  1.5669e+06, -3.2095e+06,  8.2747e+05,\n",
            "          1.9320e+05],\n",
            "        [-9.1071e+05,  3.2876e+04, -2.9399e+06, -1.4292e+06,  1.3056e+07,\n",
            "         -2.1498e+07, -5.1564e+06, -7.7101e+06,  2.4312e+07, -6.4857e+06,\n",
            "         -1.5054e+06],\n",
            "        [ 9.2732e+05, -6.6393e+04, -6.1477e+06,  2.2568e+06, -2.1498e+07,\n",
            "          4.0084e+07,  1.1766e+07, -2.1494e+07, -1.4222e+07,  5.0907e+06,\n",
            "          1.1603e+06],\n",
            "        [-2.1825e+05, -2.4185e+04, -9.0561e+06,  4.9524e+05, -5.1564e+06,\n",
            "          1.1766e+07,  5.3754e+06, -2.9428e+07,  1.5746e+07, -2.9143e+06,\n",
            "         -6.9030e+05],\n",
            "        [ 6.1188e+06,  1.0335e+05,  1.0457e+08,  1.5669e+06, -7.7101e+06,\n",
            "         -2.1494e+07, -2.9428e+07,  3.2474e+08, -2.6296e+08,  5.7308e+07,\n",
            "          1.3533e+07],\n",
            "        [-6.0279e+06, -3.6635e+04, -8.5346e+07, -3.2095e+06,  2.4312e+07,\n",
            "         -1.4222e+07,  1.5746e+07, -2.6296e+08,  2.3894e+08, -5.3675e+07,\n",
            "         -1.2659e+07],\n",
            "        [ 1.4172e+06, -3.2503e+03,  1.7266e+07,  8.2747e+05, -6.4857e+06,\n",
            "          5.0907e+06, -2.9143e+06,  5.7308e+07, -5.3675e+07,  1.2396e+07,\n",
            "          2.8529e+06],\n",
            "        [ 3.1898e+05,  1.9129e+03,  4.4669e+06,  1.9320e+05, -1.5054e+06,\n",
            "          1.1603e+06, -6.9030e+05,  1.3533e+07, -1.2659e+07,  2.8529e+06,\n",
            "          6.7832e+05]], device='cuda:0'), 'r_mat': tensor([[ 3.1799e+02, -2.0362e+01,  5.4942e+02, -3.2200e-01, -8.3431e+00,\n",
            "          4.4044e+01,  9.1907e+00, -6.9093e+01,  2.6287e+01,  8.1058e+02,\n",
            "         -7.0008e+01],\n",
            "        [-2.0362e+01,  5.3769e+00,  7.7223e+02, -6.0717e-02,  7.1563e-01,\n",
            "         -2.4708e+00, -6.9035e-01,  4.8194e+00, -2.6327e+00, -1.7903e+02,\n",
            "          9.8721e-01],\n",
            "        [ 5.4942e+02,  7.7223e+02,  2.4846e+05, -6.7860e+00,  1.5590e+02,\n",
            "         -7.7745e+02, -1.1130e+01,  4.6998e+02,  1.7443e+02, -2.0355e+04,\n",
            "         -7.1027e+02],\n",
            "        [-3.2200e-01, -6.0717e-02, -6.7860e+00,  2.1503e+02, -1.7308e+03,\n",
            "          3.0028e+03,  9.8463e+02, -2.9304e+03,  5.7190e+02, -1.6567e+02,\n",
            "         -1.2646e+01],\n",
            "        [-8.3431e+00,  7.1563e-01,  1.5590e+02, -1.7308e+03,  1.8144e+04,\n",
            "         -4.1414e+04, -9.3125e+03,  3.7267e+04, -5.7736e+03,  1.8156e+03,\n",
            "          1.4905e+02],\n",
            "        [ 4.4044e+01, -2.4708e+00, -7.7745e+02,  3.0028e+03, -4.1414e+04,\n",
            "          1.4245e+05,  1.7470e+04, -1.1654e+05,  1.2181e+04, -6.5091e+03,\n",
            "         -5.1460e+02],\n",
            "        [ 9.1907e+00, -6.9035e-01, -1.1130e+01,  9.8463e+02, -9.3125e+03,\n",
            "          1.7470e+04,  8.1018e+03, -2.8359e+04,  1.0103e+04, -1.0472e+03,\n",
            "         -1.4378e+02],\n",
            "        [-6.9093e+01,  4.8194e+00,  4.6998e+02, -2.9304e+03,  3.7267e+04,\n",
            "         -1.1654e+05, -2.8359e+04,  1.7877e+05, -5.6879e+04,  7.6868e+03,\n",
            "          1.0038e+03],\n",
            "        [ 2.6287e+01, -2.6327e+00,  1.7443e+02,  5.7190e+02, -5.7736e+03,\n",
            "          1.2181e+04,  1.0103e+04, -5.6879e+04,  4.0989e+04, -2.9887e+03,\n",
            "         -5.4833e+02],\n",
            "        [ 8.1058e+02, -1.7903e+02, -2.0355e+04, -1.6567e+02,  1.8156e+03,\n",
            "         -6.5091e+03, -1.0472e+03,  7.6868e+03, -2.9887e+03,  9.8647e+04,\n",
            "          6.5142e+03],\n",
            "        [-7.0008e+01,  9.8721e-01, -7.1027e+02, -1.2646e+01,  1.4905e+02,\n",
            "         -5.1460e+02, -1.4378e+02,  1.0038e+03, -5.4833e+02,  6.5142e+03,\n",
            "          1.1890e+03]], device='cuda:0'), 's_mat': tensor([[ 1.8603e+01, -2.1653e+00,  2.1706e+02, -3.7845e+00,  1.3706e+02,\n",
            "         -2.9427e+02,  2.0841e+01, -6.4739e+01, -4.2548e+01,  3.5144e+02,\n",
            "         -3.4331e+01],\n",
            "        [-2.1653e+00,  6.5502e-01, -3.0104e+01,  3.0231e+00, -2.3930e+01,\n",
            "          2.5981e+01, -5.2800e+00,  3.8784e+01, -6.2782e+00, -1.6464e+02,\n",
            "         -1.0360e+01],\n",
            "        [ 2.1706e+02, -3.0104e+01,  4.2037e+04,  2.5948e+02, -2.2770e+03,\n",
            "          8.4336e+03, -7.1921e+02, -6.2036e+03, -1.5710e+04,  3.7389e+04,\n",
            "         -6.1501e+03],\n",
            "        [-3.7845e+00,  3.0231e+00,  2.5948e+02,  4.3918e+01, -1.9025e+02,\n",
            "          2.3892e+02, -4.9954e+01,  2.2982e+02, -2.2086e+02, -8.7679e+02,\n",
            "         -1.5091e+02],\n",
            "        [ 1.3706e+02, -2.3930e+01, -2.2770e+03, -1.9025e+02,  2.5389e+03,\n",
            "         -5.6815e+03,  3.7777e+02, -1.3837e+02,  1.0217e+03, -4.7436e+03,\n",
            "          1.1255e+02],\n",
            "        [-2.9427e+02,  2.5981e+01,  8.4336e+03,  2.3892e+02, -5.6815e+03,\n",
            "          1.7321e+04, -6.5723e+02, -3.3586e+03, -2.4475e+03,  1.7915e+04,\n",
            "          1.6325e+02],\n",
            "        [ 2.0841e+01, -5.2800e+00, -7.1921e+02, -4.9954e+01,  3.7777e+02,\n",
            "         -6.5723e+02,  1.4462e+02, -2.2977e+02,  6.3287e+02,  1.3534e+03,\n",
            "          3.0818e+02],\n",
            "        [-6.4739e+01,  3.8784e+01, -6.2036e+03,  2.2982e+02, -1.3837e+02,\n",
            "         -3.3586e+03, -2.2977e+02,  6.9315e+03, -8.7687e+02, -2.3312e+04,\n",
            "         -1.8873e+03],\n",
            "        [-4.2548e+01, -6.2782e+00, -1.5710e+04, -2.2086e+02,  1.0217e+03,\n",
            "         -2.4475e+03,  6.3287e+02, -8.7687e+02,  9.4564e+03, -1.8039e+03,\n",
            "          4.7263e+03],\n",
            "        [ 3.5144e+02, -1.6464e+02,  3.7389e+04, -8.7679e+02, -4.7436e+03,\n",
            "          1.7915e+04,  1.3534e+03, -2.3312e+04, -1.8039e+03,  2.7102e+05,\n",
            "          1.0843e+04],\n",
            "        [-3.4331e+01, -1.0360e+01, -6.1501e+03, -1.5091e+02,  1.1255e+02,\n",
            "          1.6325e+02,  3.0818e+02, -1.8873e+03,  4.7263e+03,  1.0843e+04,\n",
            "          3.0145e+03]], device='cuda:0')}\n"
          ]
        }
      ],
      "source": [
        "cov_result = model.descale().covariance_step()\n",
        "print(cov_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHHHbiLlc-gK",
        "outputId": "a7359835-5d14-40c2-92cc-2642124f6da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "pred_function_module.theta_0.parameter_value\n",
            "1.4903191940893723\n",
            "pred_function_module.theta_1.parameter_value\n",
            "32.46531960552304\n",
            "pred_function_module.theta_2.parameter_value\n",
            "0.08726725546527295\n",
            "pred_function_module.eta_0.parameter_values.1\n",
            "-0.09695220144893717\n",
            "pred_function_module.eta_0.parameter_values.2\n",
            "0.34226750775831866\n",
            "pred_function_module.eta_0.parameter_values.3\n",
            "0.4257257301188131\n",
            "pred_function_module.eta_0.parameter_values.4\n",
            "-0.3396795174421511\n",
            "pred_function_module.eta_0.parameter_values.5\n",
            "-0.025455512759810485\n",
            "pred_function_module.eta_0.parameter_values.6\n",
            "-0.4662754004253999\n",
            "pred_function_module.eta_0.parameter_values.7\n",
            "-0.8582128169233869\n",
            "pred_function_module.eta_0.parameter_values.8\n",
            "-0.05623675701512883\n",
            "pred_function_module.eta_0.parameter_values.9\n",
            "1.391493465428994\n",
            "pred_function_module.eta_0.parameter_values.10\n",
            "-0.7090186135372448\n",
            "pred_function_module.eta_0.parameter_values.11\n",
            "0.8910585471605555\n",
            "pred_function_module.eta_0.parameter_values.12\n",
            "-0.4984640684364717\n",
            "pred_function_module.eta_1.parameter_values.1\n",
            "-0.18927040161386907\n",
            "pred_function_module.eta_1.parameter_values.2\n",
            "0.0576798599866471\n",
            "pred_function_module.eta_1.parameter_values.3\n",
            "0.04643818232748745\n",
            "pred_function_module.eta_1.parameter_values.4\n",
            "-0.04070561074981247\n",
            "pred_function_module.eta_1.parameter_values.5\n",
            "-0.10887851188977453\n",
            "pred_function_module.eta_1.parameter_values.6\n",
            "0.1416874838982529\n",
            "pred_function_module.eta_1.parameter_values.7\n",
            "0.004990041280900109\n",
            "pred_function_module.eta_1.parameter_values.8\n",
            "0.07438228179616442\n",
            "pred_function_module.eta_1.parameter_values.9\n",
            "0.18288781734697793\n",
            "pred_function_module.eta_1.parameter_values.10\n",
            "-0.21321586444529217\n",
            "pred_function_module.eta_1.parameter_values.11\n",
            "0.1800438950593008\n",
            "pred_function_module.eta_1.parameter_values.12\n",
            "-0.13607120223643088\n",
            "pred_function_module.eta_2.parameter_values.1\n",
            "-0.2847465429376822\n",
            "pred_function_module.eta_2.parameter_values.2\n",
            "0.045474064738003986\n",
            "pred_function_module.eta_2.parameter_values.3\n",
            "-0.013697635736945617\n",
            "pred_function_module.eta_2.parameter_values.4\n",
            "0.015816159442237295\n",
            "pred_function_module.eta_2.parameter_values.5\n",
            "-0.09281882268494875\n",
            "pred_function_module.eta_2.parameter_values.6\n",
            "0.22753764505962257\n",
            "pred_function_module.eta_2.parameter_values.7\n",
            "0.14408173691156229\n",
            "pred_function_module.eta_2.parameter_values.8\n",
            "0.07450289339192222\n",
            "pred_function_module.eta_2.parameter_values.9\n",
            "-0.018194444168651226\n",
            "pred_function_module.eta_2.parameter_values.10\n",
            "-0.14992929096077542\n",
            "pred_function_module.eta_2.parameter_values.11\n",
            "0.07559419906972624\n",
            "pred_function_module.eta_2.parameter_values.12\n",
            "-0.023612760080840588\n",
            "omega.parameter_values.0\n",
            "[ 0.43874562  0.05738578  0.01968844 -0.00677784  0.01180558  0.02040643]\n",
            "sigma.parameter_values.0\n",
            "[0.01757924 0.07793972]\n"
          ]
        }
      ],
      "source": [
        "for (name, para) in model.to('cpu').named_parameters():\n",
        "    print(name)\n",
        "    print(para.detach().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LT4CausXBATw"
      },
      "source": [
        "#Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xM7WITN9c_pA",
        "outputId": "fdf00ec8-4b16-4293-9a91-e76b11fdb296"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10584/2544648822.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCSVDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_file_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msimulation_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimulate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msimulation_result\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'times'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\models.py\u001b[0m in \u001b[0;36msimulate\u001b[1;34m(self, dataset, repeat)\u001b[0m\n\u001b[0;32m    394\u001b[0m                         \u001b[0meps_parameter_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0meps_value\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0meps_i\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 396\u001b[1;33m                     \u001b[0mr\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred_function_module\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m                     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'y_pred'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\predfunction.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimes\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m             \u001b[0mf_cur\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_calculate_preds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mparameters_sliced\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m             \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf_pre\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf_cur\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10584/4274769891.py\u001b[0m in \u001b[0;36m_calculate_preds\u001b[1;34m(self, t, amt, rate, **para)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;31m# return (dose / v * k_a) / (k_a - k_e) * (tc.exp(-k_e*t) - tc.exp(-k_a*t))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;31m############ Sympy Version Function #############\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[0mcomps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgut_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_e\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcomps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torchpm\\linearode.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, t, k01, k11, dose)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_01\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk_11\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mk11\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;31m#TODO sympy 수식 저장해서 불러오기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, **symbols)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nodes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, memodict)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mmemodict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_torch_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sympytorch\\sympy_module.py\u001b[0m in \u001b[0;36mfn_\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfn_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfn_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ],
      "source": [
        "tc.manual_seed(42)\n",
        "dataset = CSVDataset(dataset_file_path, column_names, device=tc.device('cpu'))\n",
        "simulation_result = model.to('cpu').simulate(dataset, 300)\n",
        "\n",
        "for id, time_data in simulation_result['times'].items() :\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(1, 1, 1)\n",
        "    print('id', id)\n",
        "    \n",
        "    p95 = np.percentile(tc.stack(simulation_result['preds'][id]), 95, 0)\n",
        "    p50 = np.percentile(tc.stack(simulation_result['preds'][id]), 50, 0)\n",
        "    average = np.average(tc.stack(simulation_result['preds'][id]), 0)\n",
        "    p5 = np.percentile(tc.stack(simulation_result['preds'][id]), 5, 0)\n",
        "    \n",
        "    ax.plot(time_data.to('cpu'), p95, color=\"black\")\n",
        "    ax.plot(time_data.to('cpu'), p50, color=\"green\")\n",
        "    ax.plot(time_data.to('cpu'), average, color=\"red\")\n",
        "    ax.plot(time_data.to('cpu'), p5, color=\"black\")\n",
        "    \n",
        "    for y_pred in simulation_result['preds'][id] :\n",
        "        ax.plot(time_data.to('cpu'), y_pred.detach().to('cpu'), marker='.', linestyle='', color='gray')\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM4W1KPEkelAM2Vf6SFmZfb",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "torchpm test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
