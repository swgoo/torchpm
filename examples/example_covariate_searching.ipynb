{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeoun9/torchpm/blob/main/examples/example_covariate_searching.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchpm in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0.3)\n",
            "Requirement already satisfied: sympytorch>=0.1.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm) (0.1.1)\n",
            "Requirement already satisfied: sympy>=1.7.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm) (1.10)\n",
            "Requirement already satisfied: torchdiffeq>=0.2.1 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm) (0.2.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm) (1.22.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchpm) (1.11.0+cu113)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy>=1.7.1->torchpm) (1.2.1)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.3.0->torchpm) (4.1.1)\n",
            "Requirement already satisfied: scipy>=1.4.0 in c:\\users\\sungwoo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torchdiffeq>=0.2.1->torchpm) (1.8.0)\n"
          ]
        }
      ],
      "source": [
        "# ! pip install git+https://github.com/yeoun9/torchpm.git\n",
        "! pip install torchpm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WllWbwIhca9I"
      },
      "outputs": [],
      "source": [
        "from torchpm import *\n",
        "from torchpm.data import CSVDataset\n",
        "from torchpm.parameter import *\n",
        "from torchpm import covariate\n",
        "import torch as tc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from scipy.stats import zmap\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run(seed):\n",
        "    np.set_printoptions(threshold=sys.maxsize)\n",
        "    np.random.seed(seed)\n",
        "    dataset_file_path = 'https://raw.githubusercontent.com/yeoun9/torchpm/main/examples/THEO.csv'\n",
        "    dataset_np = np.loadtxt(dataset_file_path, delimiter=',', dtype=np.float32, skiprows=1)\n",
        "    column_names = ['ID', 'AMT', 'TIME', 'DV', 'CMT', \"MDV\", \"RATE\", 'BWT_Norm']\n",
        "\n",
        "    ids, ids_start_idx = np.unique(dataset_np[:, column_names.index('ID')], return_index=True)\n",
        "\n",
        "\n",
        "    def set_data(dataset_np, ids_start_idx, data_for_each_id, comlumn_name, column_names) :\n",
        "        column_index = column_names.index(comlumn_name)\n",
        "        for i, start_idx in enumerate(ids_start_idx):\n",
        "            \n",
        "            if i >= len(ids_start_idx) - 2 : \n",
        "                indice = slice(start_idx,record_length)\n",
        "            else : \n",
        "                indice = slice(start_idx,ids_start_idx[i+1])    \n",
        "            dataset_np[indice, column_index] = data_for_each_id[i]\n",
        "        return dataset_np\n",
        "\n",
        "\n",
        "    record_length = len(dataset_np)\n",
        "    dataset_np_splited_by_id = np.split(dataset_np, ids_start_idx[1:])\n",
        "\n",
        "\n",
        "    bwt_index = column_names.index('BWT_Norm')\n",
        "    bwt_each_id = []\n",
        "    for data_by_id in dataset_np_splited_by_id :\n",
        "        bwt_each_id.append(data_by_id[0,bwt_index])\n",
        "    bwt_each_id = zmap(bwt_each_id, bwt_each_id)\n",
        "\n",
        "    dataset_np = set_data(dataset_np, ids_start_idx, bwt_each_id, 'BWT_Norm', column_names)\n",
        "\n",
        "\n",
        "    column_names.append('fixed')\n",
        "    fixed = np.zeros([record_length,1], dtype=np.float32)\n",
        "    dataset_np = np.hstack([dataset_np,fixed])\n",
        "\n",
        "\n",
        "    column_names.append('rand-1+1')\n",
        "    fixed = np.zeros([record_length,1], dtype=np.float32)\n",
        "    dataset_np = np.hstack([dataset_np,fixed])\n",
        "    random_for_id = (np.random.rand(12) - 0.5)*2\n",
        "    dataset_np = set_data(dataset_np, ids_start_idx, random_for_id, 'rand-1+1', column_names)\n",
        "\n",
        "    column_names.append('norm(0,1)')\n",
        "    fixed = np.zeros([record_length,1], dtype=np.float32)\n",
        "    dataset_np = np.hstack([dataset_np,fixed])\n",
        "    norm_for_id = np.random.normal(0, 1, 12)\n",
        "    dataset_np = set_data(dataset_np, ids_start_idx, norm_for_id, 'norm(0,1)', column_names)\n",
        "\n",
        "\n",
        "    def add_cor(cor_value, dataset_np) :\n",
        "        fixed = np.zeros([record_length,1], dtype=np.float32)\n",
        "        dataset_np = np.hstack([dataset_np,fixed])\n",
        "        cor_value = cor_value\n",
        "        column_names.append('BWT_Cor_'+str(cor_value))\n",
        "        BWT_Cor_for_id = cor_value*bwt_each_id + np.random.normal(0, 1, 12) * np.sqrt(1-cor_value**2)\n",
        "        dataset_np = set_data(dataset_np, ids_start_idx, BWT_Cor_for_id, 'BWT_Cor_'+str(cor_value), column_names)\n",
        "        return dataset_np\n",
        "\n",
        "    for i in [1, 5]:\n",
        "        dataset_np = add_cor(i/10, dataset_np)\n",
        "\n",
        "    device = tc.device(\"cuda:0\" if tc.cuda.is_available() else \"cpu\")\n",
        "    dataset = CSVDataset(dataset_np, column_names, device)\n",
        "\n",
        "    class BasementModel(predfunction.PredictionFunctionByTime) :\n",
        "        \n",
        "        def _set_estimated_parameters(self):\n",
        "            self.theta_0 = Theta(0., 1.5, 10.)\n",
        "            self.theta_1 = Theta(0., 30., 100.)\n",
        "            self.theta_2 = Theta(0, 0.08, 1)\n",
        "\n",
        "            self.eta_0 = Eta()\n",
        "            self.eta_1 = Eta()\n",
        "            self.eta_2 = Eta()\n",
        "\n",
        "            self.eps_0 = Eps()\n",
        "            self.eps_1 = Eps()\n",
        "\n",
        "            self.gut_model = linearode.Comp1GutModelFunction()\n",
        "        \n",
        "        def _calculate_parameters(self, covariates):\n",
        "            covariates['k_a'] = self.theta_0()*tc.exp(self.eta_0())\n",
        "            covariates['v'] = self.theta_1()*tc.exp(self.eta_1())#*para['BWT']/70\n",
        "            covariates['k_e'] = self.theta_2()*tc.exp(self.eta_2())\n",
        "            covariates['AMT'] = tc.tensor(320., device=self.dataset.device)\n",
        "\n",
        "        def _calculate_preds(self, t, p):\n",
        "            dose = p['AMT'][0]\n",
        "            k_a = p['k_a']\n",
        "            v = p['v']\n",
        "            k_e = p['k_e']\n",
        "            comps = self.gut_model(t, k_a, k_e, dose)\n",
        "            return comps[1]/v\n",
        "            \n",
        "        def _calculate_error(self, y_pred, p):\n",
        "            p['v_v'] = p['v'] \n",
        "            return y_pred +  y_pred * self.eps_0() + self.eps_1()\n",
        "\n",
        "    dependent_parameter_names = ['k_a', 'v', 'k_e']\n",
        "    dependent_parameter_initial_values = [[0,1.4901,2],[30,32.4667,34],[0,0.08,0.1]]\n",
        "    independent_parameter_names = column_names[column_names.index('BWT_Norm'):]\n",
        "\n",
        "    searcher = covariate.DeepCovariateSearching(dataset=dataset,\n",
        "                                    BaseModel=BasementModel,\n",
        "                                    dependent_parameter_names=dependent_parameter_names,\n",
        "                                    independent_parameter_names=independent_parameter_names,\n",
        "                                    dependent_parameter_initial_values=dependent_parameter_initial_values,\n",
        "                                    eps_names=['eps_0', 'eps_1'],\n",
        "                                    omega = Omega([0.4397,\n",
        "                                                    0.0575,  0.0198, \n",
        "                                                    -0.0069,  0.0116,  0.0205], False, requires_grads=True),\n",
        "                                    sigma = Sigma([[0.0177], [0.0762]], [True, True], requires_grads=[True, True]))\n",
        "    result = searcher.run(tolerance_grad=1e-3, tolerance_change=1e-3)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSError:\n",
        "        print ('Error: Creating directory. ' +  directory)\n",
        " \n",
        "createFolder('covariate_searching_result')\n",
        "\n",
        "for seed in range(0,200):\n",
        "    try :\n",
        "        file_list = os.listdir('covariate_searching_result')\n",
        "        result_file_list = [k for k in file_list if 'seed' in k]\n",
        "        if len(result_file_list) > 99 : break\n",
        "        \n",
        "        result = run(seed)\n",
        "        with open('covariate_searching_result/seed' + str(seed) +'.pkl', 'wb') as fp:\n",
        "            pickle.dump(result, fp)\n",
        "    except :\n",
        "        print('error')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "counts for selected covariate in 100 times covariate searching\n",
            "[('BWT_Norm', 82), ('BWT_Cor_0.5', 71), ('BWT_Cor_0.1', 63), ('rand-1+1', 62), ('norm(0,1)', 55)]\n",
            "['BWT_Norm', 'norm(0,1)', 'BWT_Cor_0.5']\n",
            "{'loss': 69.52711486816406, 'removed covariates': [], 'loss difference': 0.0, '>3.84': 'False', 'selected': 'removed'}\n",
            "{'loss': 80.7589340209961, 'removed covariates': ['BWT_Norm'], 'loss difference': 11.231819152832031, '>3.84': 'True', 'selected': 'selected'}\n",
            "{'loss': 69.52711486816406, 'removed covariates': [], 'loss difference': -11.231819152832031, '>3.84': '', 'selected': ''}\n",
            "{'loss': 69.49146270751953, 'removed covariates': ['fixed'], 'loss difference': -0.03565216064453125, '>3.84': 'False', 'selected': 'removed'}\n",
            "{'loss': 72.25386047363281, 'removed covariates': ['fixed', 'rand-1+1'], 'loss difference': 2.7623977661132812, '>3.84': 'False', 'selected': 'removed'}\n",
            "{'loss': 77.00479125976562, 'removed covariates': ['fixed', 'rand-1+1', 'norm(0,1)'], 'loss difference': 4.7509307861328125, '>3.84': 'True', 'selected': 'selected'}\n",
            "{'loss': 72.25386047363281, 'removed covariates': ['fixed', 'rand-1+1'], 'loss difference': -4.7509307861328125, '>3.84': '', 'selected': ''}\n",
            "{'loss': 75.54219055175781, 'removed covariates': ['fixed', 'rand-1+1', 'BWT_Cor_0.1'], 'loss difference': 3.288330078125, '>3.84': 'False', 'selected': 'removed'}\n",
            "{'loss': 79.5299301147461, 'removed covariates': ['fixed', 'rand-1+1', 'BWT_Cor_0.1', 'BWT_Cor_0.5'], 'loss difference': 3.9877395629882812, '>3.84': 'True', 'selected': 'selected'}\n",
            "{'loss': 75.54219055175781, 'removed covariates': ['fixed', 'rand-1+1', 'BWT_Cor_0.1'], 'loss difference': -3.9877395629882812, '>3.84': '', 'selected': ''}\n"
          ]
        }
      ],
      "source": [
        "cov_dict = {}\n",
        "count = 0\n",
        "for i in range(130):\n",
        "    try :\n",
        "    \n",
        "        with open('covariate_searching_result/seed' + str(i) + '.pkl', 'rb') as fp:\n",
        "            data = pickle.load(fp)\n",
        "        for cov_name in data['selected covariates']:\n",
        "            if cov_name not in cov_dict.keys() :\n",
        "                cov_dict[cov_name] = 1\n",
        "            else :\n",
        "                cov_dict[cov_name] += 1\n",
        "        count += 1\n",
        "    except:\n",
        "        pass\n",
        "print(count)\n",
        "print(\"counts for selected covariate in\", count, \"times covariate searching\")\n",
        "sorted_dict = sorted(cov_dict.items(), key = lambda item: item[1], reverse = True)\n",
        "print(sorted_dict)\n",
        "with open('covariate_searching_result/seed' + str(4) + '.pkl', 'rb') as fp:\n",
        "    data = pickle.load(fp)\n",
        "print(data['selected covariates'])\n",
        "\n",
        "for i, record in enumerate(data['history']) :\n",
        "    data['history'][i]['>3.84'] = str(record['loss difference'] > 3.84)\n",
        "    data['history'][i]['selected'] = 'selected' if record['loss difference'] > 3.84 else 'removed'\n",
        "\n",
        "for i, record in enumerate(data['history']) :\n",
        "    if i > 0 :\n",
        "        if data['history'][i-1]['selected'] == 'selected' :\n",
        "            record['selected'] = ''\n",
        "            record['>3.84'] = \"\"\n",
        "    print(record)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM4W1KPEkelAM2Vf6SFmZfb",
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "torchpm test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
